<!DOCTYPE html>
<html lang="fr" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>R√©tropropagation - Deep Learning</title>

    <link rel="stylesheet" href="../../../../../lib/theme.css">
    <link rel="stylesheet" href="../../_shared/deep-learning.css">
    <script src="https://cdn.tailwindcss.com"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script type="module">
        import { initSlide, sendTOC, setupScrollHandler } from '../../../../../parcours/_shared/slide-utils.js';
        initSlide();
        setupScrollHandler();
        sendTOC([
            { id: 'chain-rule', label: 'R√®gle de la Cha√Æne', icon: 'üîó' },
            { id: 'calcul', label: 'Calcul √âtape par √âtape', icon: 'üìù' },
        ]);
    </script>
</head>
<body class="antialiased selection:bg-blue-500 selection:text-white">

    <main class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-16">

        <section id="backprop" class="mb-16">
            <div class="flex items-center gap-3 mb-6">
                <span class="text-3xl">‚¨ÖÔ∏è</span>
                <h2 class="text-3xl font-bold dl-text-primary">La R√©tropropagation</h2>
            </div>

            <div class="prose-content dl-text-secondary">
                <p class="mb-6">
                    Maintenant, la question cl√© : <strong>comment ajuster chaque poids pour r√©duire l'erreur ?</strong>
                </p>

                <p class="mb-6">
                    On doit calculer la <strong>d√©riv√©e partielle</strong> de la perte par rapport √† chaque poids : \(\frac{\partial L}{\partial w}\). Cette valeur nous dit : "si je bouge ce poids un tout petit peu, de combien l'erreur va-t-elle changer ?"
                </p>

                <div id="chain-rule" class="concept-box scroll-mt-24">
                    <h4 class="font-bold text-blue-400 mb-3">La R√®gle de la Cha√Æne (Chain Rule)</h4>
                    <p class="dl-text-secondary text-sm mb-4">
                        C'est l'outil math√©matique fondamental. Si \(L\) d√©pend de \(a\), qui d√©pend de \(z\), qui d√©pend de \(w\), alors :
                    </p>
                    <div class="math-block text-center">
                        $$ \frac{\partial L}{\partial w} = \frac{\partial L}{\partial a} \cdot \frac{\partial a}{\partial z} \cdot \frac{\partial z}{\partial w} $$
                    </div>
                    <p class="dl-text-muted text-xs mt-3">
                        On d√©compose un calcul complexe en une s√©rie de calculs simples, multipli√©s ensemble.
                    </p>
                </div>

                <h3 id="calcul" class="text-xl font-bold dl-text-primary mt-10 mb-4 scroll-mt-24">Le Calcul √âtape par √âtape</h3>

                <div class="step-indicator">
                    <span class="step-number">1</span>
                    <span class="dl-text-primary font-semibold">Erreur de sortie</span>
                </div>
                <p class="mb-4 ml-10">
                    On commence par la fin. Pour la derni√®re couche :
                </p>
                <div class="math-block text-sm">
                    $$ \delta^{[L]} = \frac{\partial L}{\partial a^{[L]}} = -(y - \hat{y}) $$
                </div>

                <div class="step-indicator">
                    <span class="step-number">2</span>
                    <span class="dl-text-primary font-semibold">Propagation arri√®re de l'erreur</span>
                </div>
                <p class="mb-4 ml-10">
                    Pour chaque couche pr√©c√©dente, on "propage" l'erreur en arri√®re :
                </p>
                <div class="math-block text-sm">
                    $$ \delta^{[l]} = \delta^{[l+1]} \cdot W^{[l+1]} \cdot \sigma'(z^{[l]}) $$
                </div>
                <p class="mb-6 ml-10 text-sm dl-text-muted">
                    O√π \(\sigma'(z)\) est la d√©riv√©e de la fonction d'activation. Pour tanh : \(\sigma'(z) = 1 - \tanh^2(z)\).
                </p>

                <div class="step-indicator">
                    <span class="step-number">3</span>
                    <span class="dl-text-primary font-semibold">Calcul des gradients</span>
                </div>
                <p class="mb-4 ml-10">
                    Maintenant qu'on a les \(\delta\) pour chaque couche, on calcule le gradient pour chaque poids :
                </p>
                <div class="math-block text-sm">
                    $$ \frac{\partial L}{\partial W^{[l]}} = \delta^{[l]} \cdot (a^{[l-1]})^T $$
                    <p class="dl-text-muted text-xs mt-2">
                        Le gradient d'un poids = erreur locale √ó entr√©e de ce poids
                    </p>
                </div>

                <div class="analogy-box">
                    <div class="flex items-start gap-3">
                        <span class="text-2xl">üí°</span>
                        <div>
                            <h4 class="font-bold text-green-400 mb-2">Analogie : Le jeu du t√©l√©phone invers√©</h4>
                            <p class="dl-text-secondary text-sm">
                                Imaginez une file de personnes. Le dernier re√ßoit un message "tu t'es tromp√© de X". Il chuchote √† la personne devant lui "c'est en partie ta faute". Cette personne calcule sa part de responsabilit√© et transmet le message. √Ä la fin, chaque personne sait <strong>√† quel point elle a contribu√©</strong> √† l'erreur finale.
                            </p>
                        </div>
                    </div>
                </div>

                <div class="warning-box">
                    <div class="flex items-start gap-3">
                        <span class="text-2xl">‚ö†Ô∏è</span>
                        <div>
                            <h4 class="font-bold text-yellow-500 mb-2">Pourquoi c'est efficace ?</h4>
                            <p class="dl-text-secondary text-sm">
                                L'alternative na√Øve serait de calculer la d√©riv√©e pour chaque poids <strong>ind√©pendamment</strong>, en faisant une forward pass √† chaque fois. Avec 1 million de poids, cela ferait 1 million de forward passes ! La backprop fait le m√™me travail en <strong>1 forward pass + 1 backward pass</strong>. C'est un gain de temps gigantesque.
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </section>

    </main>

    <footer class="dl-footer border-t py-8 text-center text-sm">
        <p>Deep Learning pour l'impatient ‚Äî Slide 4/7</p>
    </footer>

</body>
</html>
